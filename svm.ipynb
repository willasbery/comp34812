{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Text processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configuration\n",
    "DATA_DIR = Path('./data')\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "DEV_PATH = DATA_DIR / 'dev.csv'\n",
    "MODEL_SAVE_PATH = Path('./models')\n",
    "MODEL_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_TRIALS = 25  # Number of Optuna trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Determine the device to use for computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_df, dev_df):\n",
    "    \"\"\"Prepare data for SVM training.\"\"\"\n",
    "    # Combine claim and evidence into a single text feature for TF-IDF\n",
    "    train_df['text'] = train_df['Claim'] + \" [SEP] \" + train_df['Evidence']\n",
    "    dev_df['text'] = dev_df['Claim'] + \" [SEP] \" + dev_df['Evidence']\n",
    "    \n",
    "    # Extract labels\n",
    "    train_labels = train_df['label'].values\n",
    "    dev_labels = dev_df['label'].values\n",
    "    \n",
    "    return train_df, dev_df, train_labels, dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # remove special chars\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([self.lemmatizer.lemmatize(w) for w in words])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return [self.preprocess(text) for text in X]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.preprocess(text) for text in X]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def fit_transform(self, X, y=None):\n",
    "        features = []\n",
    "        \n",
    "        for text in X:\n",
    "            claim, evidence = text.split(\"[SEP]\")\n",
    "            \n",
    "            feature_dict = {\n",
    "                'text_length': len(text),\n",
    "                'claim_length': len(claim),\n",
    "                'evidence_length': len(evidence),\n",
    "                'word_overlap': len(set(claim.split()) & set(evidence.split())),\n",
    "                'claim_words': len(claim.split()),\n",
    "                'evidence_words': len(evidence.split())\n",
    "            }\n",
    "            \n",
    "            features.append(feature_dict)\n",
    "            \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.fit_transform(X)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = 0\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
    "    # Load data\n",
    "    global trial_number\n",
    "    trial_number += 1\n",
    "    \n",
    "    logging.info(\"Loading datasets...\")\n",
    "    train_df = pd.read_csv(TRAIN_PATH)\n",
    "    dev_df = pd.read_csv(DEV_PATH)\n",
    "    \n",
    "    logging.info(f\"Training data shape: {train_df.shape}\")\n",
    "    logging.info(f\"Development data shape: {dev_df.shape}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    train_df, dev_df, train_labels, dev_labels = prepare_data(train_df, dev_df)\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    C = trial.suggest_float(\"C\", 0.01, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]) if kernel in [\"rbf\", \"poly\", \"sigmoid\"] else \"scale\"\n",
    "    \n",
    "    if kernel == \"poly\":\n",
    "        degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "    else:\n",
    "        degree = 3  # Default value\n",
    "    \n",
    "    # TF-IDF vectorizer parameters\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [5000, 10000, 15000, 20000])\n",
    "    min_df = trial.suggest_categorical(\"min_df\", [1, 2, 3, 4, 5])\n",
    "    max_df = trial.suggest_categorical(\"max_df\", [0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    ngram_range = trial.suggest_categorical(\"ngram_range\", [(1, 1), (1, 2), (1, 3)])\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text_features', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(\n",
    "                    max_features=max_features,\n",
    "                    min_df=min_df,\n",
    "                    max_df=max_df,\n",
    "                    ngram_range=ngram_range,\n",
    "                    stop_words='english',\n",
    "                    analyzer='word',\n",
    "                    token_pattern=r'\\w+',\n",
    "                    sublinear_tf=True\n",
    "                ))\n",
    "            ])),\n",
    "            ('custom_features', FeatureExtractor())\n",
    "        ])),\n",
    "        ('scaler', StandardScaler(with_mean=False)),  # TF-IDF matrices are sparse\n",
    "        ('svm', SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree if kernel == \"poly\" else 3,\n",
    "            probability=True\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    logging.info(f\"Training SVM with hyperparameters: C={C}, kernel={kernel}, gamma={gamma}\")\n",
    "    pipeline.fit(train_df['text'], train_labels)\n",
    "    \n",
    "    # Evaluate on dev set\n",
    "    dev_preds = pipeline.predict(dev_df['text'])\n",
    "    accuracy = accuracy_score(dev_labels, dev_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(dev_labels, dev_preds, average='binary')\n",
    "    \n",
    "    logging.info(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    with open(f'svm_{trial_number}.json', 'w') as f:\n",
    "        json.dumps(trial.params + {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1})\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:15:42 - Using device: cpu (Note: scikit-learn SVM implementation will utilize CPU)\n",
      "[I 2025-03-26 18:15:42,305] A new study created in memory with name: svm_evidence_detection\n",
      "2025-03-26 18:15:42 - Loading datasets...\n",
      "2025-03-26 18:15:42 - Loading datasets...\n",
      "2025-03-26 18:15:42 - Loading datasets...\n",
      "2025-03-26 18:15:42 - Loading datasets...\n",
      "2025-03-26 18:15:42 - Loading datasets...\n",
      "2025-03-26 18:15:42 - Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPERPARAMETER TUNING\n",
      "=====================\n",
      "Running 25 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:15:42 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:15:42 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:15:42 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:15:42 - Development data shape: (5926, 3)\n",
      "2025-03-26 18:15:42 - Development data shape: (5926, 3)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:15:42 - Training data shape: (21508, 3)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:15:42 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:15:42 - Development data shape: (5926, 3)\n",
      "2025-03-26 18:15:42 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:15:42 - Training SVM with hyperparameters: C=98.07659333226346, kernel=rbf, gamma=auto\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:15:42 - Training SVM with hyperparameters: C=6.756447544726421, kernel=poly, gamma=auto\n",
      "2025-03-26 18:15:42 - Development data shape: (5926, 3)\n",
      "2025-03-26 18:15:42 - Development data shape: (5926, 3)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:15:42 - Development data shape: (5926, 3)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:15:42 - Training SVM with hyperparameters: C=20.180756811464974, kernel=linear, gamma=scale\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:15:43 - Training SVM with hyperparameters: C=0.07077036139456211, kernel=poly, gamma=auto\n",
      "2025-03-26 18:15:43 - Training SVM with hyperparameters: C=28.47625326650315, kernel=sigmoid, gamma=auto\n",
      "2025-03-26 18:15:43 - Training SVM with hyperparameters: C=0.39058085103774165, kernel=rbf, gamma=scale\n",
      "2025-03-26 18:43:45 - Accuracy: 0.7622, Precision: 0.8147, Recall: 0.1823, F1: 0.2980\n",
      "[I 2025-03-26 18:43:46,023] Trial 5 finished with value: 0.7622342220722241 and parameters: {'C': 0.39058085103774165, 'kernel': 'rbf', 'gamma': 'scale', 'max_features': 10000, 'min_df': 1, 'max_df': 0.8, 'ngram_range': (1, 3)}. Best is trial 5 with value: 0.7622342220722241.\n",
      "2025-03-26 18:43:46 - Loading datasets...\n",
      "2025-03-26 18:43:46 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:43:46 - Development data shape: (5926, 3)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:43:46 - Training SVM with hyperparameters: C=0.9830332888349116, kernel=linear, gamma=scale\n",
      "2025-03-26 18:48:03 - Accuracy: 0.7234, Precision: 1.0000, Recall: 0.0006, F1: 0.0012\n",
      "[I 2025-03-26 18:48:03,953] Trial 3 finished with value: 0.7234222072224097 and parameters: {'C': 0.07077036139456211, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'max_features': 5000, 'min_df': 2, 'max_df': 0.5, 'ngram_range': (1, 1)}. Best is trial 5 with value: 0.7622342220722241.\n",
      "2025-03-26 18:48:03 - Loading datasets...\n",
      "2025-03-26 18:48:04 - Training data shape: (21508, 3)\n",
      "2025-03-26 18:48:04 - Development data shape: (5926, 3)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 1) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\willi\\Desktop\\Uni\\3rd_year\\NLU\\comp38412-not-broken\\.venv\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (1, 3) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2025-03-26 18:48:04 - Training SVM with hyperparameters: C=1.138144567592586, kernel=linear, gamma=scale\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nHYPERPARAMETER TUNING\")\n",
    "    print(\"=====================\")\n",
    "    print(f\"Running {N_TRIALS} trials...\")\n",
    "    \n",
    "    # Check if GPU is available for NumPy/SciPy operations\n",
    "    device = get_device()\n",
    "    logging.info(f\"Using device: {device} (Note: scikit-learn SVM implementation will utilize CPU)\")\n",
    "    \n",
    "    # Create a study with TPE sampler and MedianPruner\n",
    "    sampler = TPESampler(seed=42)  # TPE sampler as requested\n",
    "    pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=5, interval_steps=2)\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',  # Maximize accuracy\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "        study_name='svm_evidence_detection'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective, n_trials=N_TRIALS, n_jobs=6)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Hyperparameter tuning interrupted.\")\n",
    "    \n",
    "    print(\"\\nBest trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Accuracy): {trial.value}\")\n",
    "    print(\"  Params:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:38:58 - Loading datasets...\n",
      "2025-03-26 17:38:58 - Training data shape: (21508, 3)\n",
      "2025-03-26 17:38:58 - Development data shape: (5926, 3)\n",
      "2025-03-26 17:38:58 - Training SVM with hyperparameters: C=1.0952526897000217, kernel=rbf, gamma=auto\n",
      "2025-03-26 17:52:34 - Accuracy: 0.8046, Precision: 0.7304, Recall: 0.4659, F1: 0.5689\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': 1.0952526897000217, \n",
    "    'kernel': 'rbf', \n",
    "    'gamma': 'auto', \n",
    "    'max_features': 5000, \n",
    "    'min_df': 3, \n",
    "    'ngram_range': (1, 3)\n",
    "}\n",
    "\n",
    "logging.info(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "dev_df = pd.read_csv(DEV_PATH)\n",
    "\n",
    "logging.info(f\"Training data shape: {train_df.shape}\")\n",
    "logging.info(f\"Development data shape: {dev_df.shape}\")\n",
    "\n",
    "# Prepare data\n",
    "train_df, dev_df, train_labels, dev_labels = prepare_data(train_df, dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive evaluation metrics.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all metrics\n",
    "    \"\"\"\n",
    "    # Basic accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate precision, recall, f1 (macro)\n",
    "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro'\n",
    "    )\n",
    "    \n",
    "    # Calculate precision, recall, f1 (weighted)\n",
    "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Matthews Correlation Coefficient\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro-P': macro_precision,\n",
    "        'Macro-R': macro_recall,\n",
    "        'Macro-F1': macro_f1,\n",
    "        'W Macro-P': weighted_precision,\n",
    "        'W Macro-R': weighted_recall,\n",
    "        'W Macro-F1': weighted_f1,\n",
    "        'MCC': mcc\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:52:49 - Trial Metrics: Accuracy=0.8046, Macro-F1=0.7213, W Macro-F1=0.7893, MCC=0.4695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Metric       Value   \n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy     0.8046\n",
      "Macro-P      0.7754\n",
      "Macro-R      0.7000\n",
      "Macro-F1     0.7213\n",
      "W Macro-P    0.7956\n",
      "W Macro-R    0.8046\n",
      "W Macro-F1   0.7893\n",
      "MCC          0.4695\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "_, dev_df, _, dev_labels = prepare_data(train_df, dev_df)\n",
    "\n",
    "# Example usage in your evaluation code:\n",
    "trial_preds = pipeline.predict(dev_df['text'])\n",
    "predictions = pd.DataFrame({'prediction': trial_preds})\n",
    "predictions.to_csv('predictions.csv', index=False)\n",
    "\n",
    "metrics = calculate_all_metrics(dev_labels, trial_preds)\n",
    "\n",
    "# Print metrics in tabular format\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Metric':<12} {'Value':<8}\")\n",
    "print(\"-\" * 80)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:<12} {value:.4f}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Log metrics\n",
    "logging.info(f\"Trial Metrics: Accuracy={metrics['Accuracy']:.4f}, Macro-F1={metrics['Macro-F1']:.4f}, W Macro-F1={metrics['W Macro-F1']:.4f}, MCC={metrics['MCC']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
