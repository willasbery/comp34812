{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T23:21:21.565004Z",
     "iopub.status.busy": "2025-03-25T23:21:21.564662Z",
     "iopub.status.idle": "2025-03-25T23:21:21.573259Z",
     "shell.execute_reply": "2025-03-25T23:21:21.572051Z",
     "shell.execute_reply.started": "2025-03-25T23:21:21.564977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Text processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T23:21:21.575211Z",
     "iopub.status.busy": "2025-03-25T23:21:21.574800Z",
     "iopub.status.idle": "2025-03-25T23:21:21.599082Z",
     "shell.execute_reply": "2025-03-25T23:21:21.598014Z",
     "shell.execute_reply.started": "2025-03-25T23:21:21.575170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Path configuration\n",
    "DATA_DIR = Path('./data')\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "DEV_PATH = DATA_DIR / 'dev.csv'\n",
    "MODEL_SAVE_PATH = Path('./models')\n",
    "MODEL_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_TRIALS = 25  # Number of Optuna trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T23:21:21.601832Z",
     "iopub.status.busy": "2025-03-25T23:21:21.601450Z",
     "iopub.status.idle": "2025-03-25T23:21:21.625389Z",
     "shell.execute_reply": "2025-03-25T23:21:21.624343Z",
     "shell.execute_reply.started": "2025-03-25T23:21:21.601802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Determine the device to use for computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T23:21:21.627058Z",
     "iopub.status.busy": "2025-03-25T23:21:21.626742Z",
     "iopub.status.idle": "2025-03-25T23:21:21.642532Z",
     "shell.execute_reply": "2025-03-25T23:21:21.641484Z",
     "shell.execute_reply.started": "2025-03-25T23:21:21.627007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_df, dev_df):\n",
    "    \"\"\"Prepare data for SVM training.\"\"\"\n",
    "    # Combine claim and evidence into a single text feature for TF-IDF\n",
    "    train_df['text'] = train_df['Claim'] + \" [SEP] \" + train_df['Evidence']\n",
    "    dev_df['text'] = dev_df['Claim'] + \" [SEP] \" + dev_df['Evidence']\n",
    "    \n",
    "    # Extract labels\n",
    "    train_labels = train_df['label'].values\n",
    "    dev_labels = dev_df['label'].values\n",
    "    \n",
    "    return train_df, dev_df, train_labels, dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # remove special chars\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([self.lemmatizer.lemmatize(w) for w in words])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return [self.preprocess(text) for text in X]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.preprocess(text) for text in X]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def fit_transform(self, X, y=None):\n",
    "        features = []\n",
    "        \n",
    "        for text in X:\n",
    "            claim, evidence = text.split(\"[SEP]\")\n",
    "            \n",
    "            feature_dict = {\n",
    "                'text_length': len(text),\n",
    "                'claim_length': len(claim),\n",
    "                'evidence_length': len(evidence),\n",
    "                'word_overlap': len(set(claim.split()) & set(evidence.split())),\n",
    "                'claim_words': len(claim.split()),\n",
    "                'evidence_words': len(evidence.split())\n",
    "            }\n",
    "            \n",
    "            features.append(feature_dict)\n",
    "            \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.fit_transform(X)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_all_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive evaluation metrics.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all metrics\n",
    "    \"\"\"\n",
    "    # Basic accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate precision, recall, f1 (macro)\n",
    "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro'\n",
    "    )\n",
    "    \n",
    "    # Calculate precision, recall, f1 (weighted)\n",
    "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Matthews Correlation Coefficient\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro-P': macro_precision,\n",
    "        'Macro-R': macro_recall,\n",
    "        'Macro-F1': macro_f1,\n",
    "        'W Macro-P': weighted_precision,\n",
    "        'W Macro-R': weighted_recall,\n",
    "        'W Macro-F1': weighted_f1,\n",
    "        'MCC': mcc\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T23:21:21.644080Z",
     "iopub.status.busy": "2025-03-25T23:21:21.643716Z",
     "iopub.status.idle": "2025-03-25T23:21:21.661524Z",
     "shell.execute_reply": "2025-03-25T23:21:21.660480Z",
     "shell.execute_reply.started": "2025-03-25T23:21:21.644046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trial_number = 0\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
    "    # Load data\n",
    "    global trial_number\n",
    "    trial_number += 1\n",
    "    \n",
    "    logging.info(\"Loading datasets...\")\n",
    "    train_df = pd.read_csv(TRAIN_PATH)\n",
    "    dev_df = pd.read_csv(DEV_PATH)\n",
    "    \n",
    "    logging.info(f\"Training data shape: {train_df.shape}\")\n",
    "    logging.info(f\"Development data shape: {dev_df.shape}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    train_df, dev_df, train_labels, dev_labels = prepare_data(train_df, dev_df)\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    C = trial.suggest_float(\"C\", 0.01, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]) if kernel in [\"rbf\", \"poly\", \"sigmoid\"] else \"scale\"\n",
    "    \n",
    "    if kernel == \"poly\":\n",
    "        degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "    else:\n",
    "        degree = 3  # Default value\n",
    "    \n",
    "    # TF-IDF vectorizer parameters\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [5000, 10000, 15000, 20000])\n",
    "    min_df = trial.suggest_categorical(\"min_df\", [1, 2, 3, 4, 5])\n",
    "    max_df = trial.suggest_categorical(\"max_df\", [0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    ngram_range = trial.suggest_categorical(\"ngram_range\", [(1, 1), (1, 2), (1, 3)])\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text_features', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(\n",
    "                    max_features=max_features,\n",
    "                    min_df=min_df,\n",
    "                    max_df=max_df,\n",
    "                    ngram_range=ngram_range,\n",
    "                    stop_words='english',\n",
    "                    analyzer='word',\n",
    "                    token_pattern=r'\\w+',\n",
    "                    sublinear_tf=True\n",
    "                ))\n",
    "            ])),\n",
    "            ('custom_features', FeatureExtractor())\n",
    "        ])),\n",
    "        ('scaler', StandardScaler(with_mean=False)),  # TF-IDF matrices are sparse\n",
    "        ('svm', SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree if kernel == \"poly\" else 3,\n",
    "            probability=True\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    logging.info(f\"Training SVM with hyperparameters: C={C}, kernel={kernel}, gamma={gamma}\")\n",
    "    pipeline.fit(train_df['text'], train_labels)\n",
    "    \n",
    "    # Evaluate on dev set\n",
    "    dev_preds = pipeline.predict(dev_df['text'])\n",
    "    metrics = calculate_all_metrics(dev_labels, dev_preds)\n",
    "    \n",
    "    with open(f'svm_{trial_number}.json', 'w') as f:\n",
    "        combined_results = {**metrics, **trial.params}\n",
    "        json.dumps(combined_results, f)\n",
    "    \n",
    "    return metrics[\"W Macro-F1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T23:21:21.663076Z",
     "iopub.status.busy": "2025-03-25T23:21:21.662655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nHYPERPARAMETER TUNING\")\n",
    "    print(\"=====================\")\n",
    "    print(f\"Running {N_TRIALS} trials...\")\n",
    "    \n",
    "    # Check if GPU is available for NumPy/SciPy operations\n",
    "    device = get_device()\n",
    "    logging.info(f\"Using device: {device} (Note: scikit-learn SVM implementation will utilize CPU)\")\n",
    "    \n",
    "    # Create a study with TPE sampler and MedianPruner\n",
    "    sampler = TPESampler(seed=42)  # TPE sampler as requested\n",
    "    pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=5, interval_steps=2)\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',  # Maximize accuracy\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "        study_name='svm_evidence_detection'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective, n_trials=N_TRIALS, n_jobs=6)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Hyperparameter tuning interrupted.\")\n",
    "    \n",
    "    print(\"\\nBest trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Accuracy): {trial.value}\")\n",
    "    print(\"  Params:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0.800027688418219\n",
    "best_params= {\n",
    "    'C': 70.50286208722827, \n",
    "    'kernel': 'rbf', \n",
    "    'gamma': 'scale', \n",
    "    'max_features': 5000, \n",
    "    'min_df': 4, \n",
    "    'max_df': 0.7, \n",
    "    'ngram_range': (1, 3)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6854185,
     "sourceId": 11009344,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
